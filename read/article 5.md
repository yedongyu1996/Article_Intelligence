# 融合知识图谱与大语言模型的科技文献复杂知识对象抽取研究 (2025年7月)

### 1. 研究目标 · 内容 · 问题 · 出发点

* **研究领域与背景、具体对象 / 数据集**
    * **研究领域与背景**：本研究处于智能情报分析领域，专注于科技文献的知识抽取。背景是，科技文献中蕴含着由实体、关系、数据等多种知识单元组成的“复杂知识对象”，它们是科技创新的重要要素。传统的知识抽取方法效率低、主观性强，而大语言模型（LLM）在专业领域存在知识盲区和性能损失。因此，研究旨在融合知识图谱（KG）的结构化领域知识与LLM的自然语言处理能力。
    * **具体对象 / 数据集**：研究以**有机太阳能电池（Organic Solar Cells, OSC）**领域为实例。数据集来源于Web of Science论文数据库和IncoPat专利数据库，共搜集3369篇论文和421篇专利，并从中筛选出高质量的核心数据集用于知识图谱构建与模型训练。

* **论文想解决的核心问题**
    * 如何高效、准确地从专业领域的科技文献中，自动抽取出由多个知识单元关联构成的**复杂知识对象**（如实验方案，包含实验原理、材料、步骤、结果等），以克服传统方法效率低和通用大模型在专业领域能力不足的问题。

* **研究动机 / 假设**
    * **研究动机**：现有知识抽取方法多集中于实体、关系等简单的扁平化知识，对实验方案这类具有层次、时序、多维关系的复杂知识对象抽取研究不足。同时，直接使用如ChatGPT等在线LLM服务存在数据隐私泄露风险，而本地化部署的开源模型需要适配特定领域才能发挥最佳效果。
    * **研究假设**：将领域知识图谱中蕴含的结构化、形式化知识作为先验知识，注入到本地化部署的大语言模型中，可以显著增强模型对科技文献复杂知识对象的理解和抽取能力，提升抽取结果的准确性和稳定性。

* **工作内容概览**
    * **领域知识图谱构建**：首先，通过轻量级本体建模方法构建了OSC领域的知识图谱模式层。然后，使用BRAT工具对核心数据集进行人工标注，并将标注结果存储在Neo4j图数据库中，完成实例层构建。
    * **大语言模型微调**：在本地部署开源大语言模型ChatGLM2-6B，利用前一步构建的知识图谱三元组生成指令数据集，并采用低秩适应（LoRA）技术对模型进行高效微调，使其适应OSC领域的知识抽取任务。
    * **复杂知识对象抽取**：设计了一种基于思维记忆（Memory of Thoughts, MOT）机制的提示构建策略。该策略从知识图谱中检索与当前任务最相关的问答（QA）对作为示例，注入到提示中。通过与微调后的模型进行多轮问答，分层、逐步地识别实体类型并抽取出具体的知识实体，最终依据本体模型将抽取的实体组合成复杂的知识对象。

### 2. 研究方法（含模型 / 技术详解）

* **理论框架与算法**
    * 本文提出一个融合知识图谱与大语言模型的三阶段框架。
    * **阶段一：领域知识图谱构建**。建立一个包含模式层（Ontology）和实例层（Triples）的OSC领域知识图谱。
    * **阶段二：模型微调**。使用实例层数据对本地化的ChatGLM2-6B模型进行LoRA微调。
    * **阶段三：复杂知识对象抽取**。通过一种结合多轮问答和MOT机制的提示工程方法，与微调后的LLM交互，实现知识抽取。
    * **抽取算法**：如论文表1所示，算法首先从知识图谱构建一个外部记忆模块（Memory）。对文献中的每个句子，通过与记忆模块进行相似度计算，检索出Top-k个QA对作为示例。然后构建提示，与LLM进行多轮问答：前几轮迭代地确定句子的实体类型（文本分类），最后一轮根据确定的类型抽取出细粒度实体。最终，所有抽取的实体根据本体组合成复杂知识对象。

* **关键模型/技术逐一说明**
    * **知识图谱构建（KG）**
        * **架构**：模式层（Ontology）定义了实体类型（语句级、词汇级、科学数据级）、关系和属性；实例层以三元组形式存储具体知识。
        * **流程**：使用BRAT工具对科技文献进行标注，经过专家审核后，将结果转换为三元组并导入Neo4j图数据库。
        * **优势**：为LLM提供了高质量、结构化的领域先验知识。
    * **大语言模型微调（ChatGLM2-6B + LoRA）**
        * **架构**：选择ChatGLM2-6B作为基础模型。使用LoRA（Low-Rank Adaptation）技术进行微调，该技术通过在模型中引入可训练的低秩矩阵（$A$和$B$）来模拟原始参数的更新量（$\Delta W=BA$），而无需改动原始的庞大参数。
        * **训练流程**：将KG中的三元组（实体, 属性, 属性值）转换为指令式QA对。在训练时，冻结ChatGLM2-6B的全部参数，仅更新降维矩阵A和升维矩阵B。
        * **优势与局限**：相比于全量微调，LoRA极大降低了计算资源消耗和训练参数量。相比P-Tuning v2，能更好避免“灾难性遗忘”。
    * **基于MOT机制的提示构建**
        * **架构**：MOT（Memory of Thoughts）机制的核心是构建一个外部记忆模块（Memory），并在生成提示时从中“回忆”相关知识。
        * **推理流程**：
            1.  **记忆构建与聚类**：将KG中的QA对作为记忆单元构建Memory。使用LDA主题模型将Memory划分为N个主题簇，以增强检索的多样性。
            2.  **样例检索**：对于一个待处理的句子（目标问题q），首先从N个记忆簇中各找出一个与q语义最相似的记忆。然后，从这N个候选中，再选出与q相似度最高的Top-k个作为最终的问答样例。相似度通过Doc2vec模型计算文本向量，再用余弦相似度进行评估。
            3.  **提示生成**：将检索到的Top-k问答样例与目标问题q组合成一个结构化的提示（Prompt），输入给LLM。格式为：“问答样例: [样例1, ..., 样例k] 目标问题: [q]”。
        * **优势**：通过上下文学习（In-Context Learning）的方式，利用高质量、高相关的样例引导LLM生成更准确、稳定的结果，有效缓解模型的“幻觉”问题。

* **重要公式**
    * **复杂知识对象抽取概率**：
        $$P(e|s,o) = P(type_1|p_1(s,o)) \cdot \dots \cdot P(type_n|p_n(s,o,type_{n-1})) \cdot P(e|p_{n+1}(s,o,type_n))$$
        该公式表示，抽取实体$e$的概率是多轮问答中，逐步正确识别实体类型（$type_1$到$type_n$）并最终抽取实体$e$的概率乘积。
    * **语义相似度计算**：
        $$sim(q, m) = cos(doc2vec(q), doc2vec(m))$$
        使用Doc2vec模型将目标问题$q$和记忆$m$转换为向量，并通过余弦相似度计算其语义相似性。
    * **评价指标**：
        $$P = \frac{M}{M+N}, \quad R = \frac{M}{M+T}, \quad F1 = \frac{2PR}{P+R}$$
        其中，$P$为准确率，$R$为召回率，$M$为正确预测的正例数，$N$为错报数，$T$为漏报数。

### 3. 实验设计与结果（含创新点验证）

* **实验 / 仿真 / 原型流程**
    1.  **数据集准备与KG构建**：收集OSC领域文献，由领域专家筛选出核心数据集。基于此数据集，通过两阶段轻量级本体建模方法构建OSC本体模型，再利用BRAT工具人工标注，最终生成包含4700个知识实体和15377个三元组的知识图谱，并存入Neo4j。
    2.  **模型部署与微调**：在NVIDIA A40 GPU环境下部署ChatGLM2-6B模型。将知识图谱三元组按5:1划分为训练集和测试集，并转换为QA对。使用训练集和LoRA技术对模型进行微调，监控损失函数直至收敛。
    3.  **MOT机制设置**：使用训练集的QA对构建外部记忆模块。通过计算困惑度确定LDA主题模型的最优主题数为30，对记忆进行聚类。训练Doc2vec模型用于计算文本向量。
    4.  **模型评估**：设计了四种模式进行对比实验：
        * **ChatGLM2-6B**: 基础模型，不进行任何微调。
        * **ChatGLM2-6B+LoRA1**: 使用由ChatGLM自身根据文本生成的指令集进行微调。
        * **ChatGLM2-6B+LoRA2**: 使用由知识图谱生成的指令集进行微调。
        * **ChatGLM2-6B+LoRA2+MOT**: 本文提出的完整方法，即在LoRA2的基础上，使用MOT机制构建提示。
    5.  **结果分析**：在测试集上运行四种模式，使用准确率（P）、召回率（R）和F1值作为评价指标，对比分析各模式的性能。同时，分析了最终模型对不同类型实体（语句级、词汇级、科学数据级）的抽取效果。

* **数据集、参数、评价指标**
    * **数据集**: OSC核心数据集（具体构成见论文表2），包括材料研究、制备方法、机理研究、结构研究四个方面的论文和专利。
    * **参数**:
        * **LoRA**: `lora_rank`=8, `lora_dropout`=0.1, `batch_size`=4, `learning_rate`=1e-4。
        * **MOT**: `k` (问答样例数)=3, LDA主题数=30。
        * **Doc2vec**: 向量维度=20, 迭代次数=10, 学习率=0.025。
    * **评价指标**: 准确率（Precision, P）、召回率（Recall, R）、F1值（F1-score）。

* **创新点如何得到验证，结果对比与可视化描述**
    * **创新点验证**：
        1.  **KG数据微调的有效性**：通过对比`ChatGLM2-6B+LoRA2`（F1=54.2%）和`ChatGLM2-6B+LoRA1`（F1=49.1%）的结果，证明了使用来自知识图谱的高质量、结构化数据进行微调，显著优于使用LLM自动生成的通用指令集。
        2.  **MOT机制的有效性**：通过对比`ChatGLM2-6B+LoRA2+MOT`（F1=60.1%）和`ChatGLM2-6B+LoRA2`（F1=54.2%）的结果，证明了在提示中注入领域知识样例能够进一步大幅提升模型的抽取性能。
    * **结果对比与可视化**：
        * **总体性能（论文表7）**：本文提出的`ChatGLM2-6B+LoRA2+MOT`方法在所有指标上均达到最优，F1值达到60.1%，相比基线模型ChatGLM2-6B（F1=47.8%）提升了12.3%。
        * **按实体类型分析（论文表8）**：语句级实体的抽取效果最好（F1=0.66），而词汇级和科学数据级实体的效果稍差。
        * **可视化**：论文图3展示了微调过程中损失函数的变化，验证了模型的收敛性。图4通过困惑度变化曲线确定了LDA模型的最佳主题数。图5使用t-SNE将记忆簇在二维空间中可视化，展示了明显的聚类结构。

* **主要实验结论与作者解释**
    * **结论**：融合知识图谱与大语言模型的抽取方法，在准确率、召回率和F1值上均优于仅依赖大语言模型的方法。知识图谱通过高质量的微调数据和提示阶段的知识注入，能有效增强LLM在专业领域的复杂知识抽取能力。
    * **作者解释**：词汇级和科学数据级实体抽取精度较低的原因在于**错误传播**。这两类实体位于本体结构的底层，需要经过更多轮次的问答才能定位，任何上一轮的分类错误都会被传播到下一轮，从而影响最终的抽取准确性。

### 4. 研究结论

* **重要发现（定量 / 定性）**
    * **定量**：本文提出的融合方法相较于单独使用ChatGLM2-6B模型，在准确率、召回率和F1值上分别提升了14.1%、10.3%和12.3%。
    * **定性**：实验证明，将知识图谱蕴含的领域知识以两种方式（LoRA微调和MOT提示注入）赋能大语言模型是一种行之有效的策略。它能显著提升模型在特定、专业领域进行细粒度知识挖掘的效率与准确性。

* **对学术或应用的意义**
    * **学术意义**：为解决专业领域复杂知识对象抽取问题提供了一个新的、有效的技术范式，探索了知识图谱与大语言模型深度融合的协同机制。
    * **应用意义**：该方法能够高效精准地从海量科技文献中挖掘深层知识，支撑数智驱动的科学发现，可应用于构建特定学科的知识库，辅助科研人员进行文献分析和情报挖掘。此外，该框架具有迭代优化的潜力，抽取出的新知识经审核后可反哺知识图谱。

### 5. 创新点列表

1.  **面向复杂知识对象的混合抽取框架**：提出了一种专为抽取科技文献中“复杂知识对象”（而非简单实体、关系）而设计的融合方法，该方法将知识图谱构建、大模型微调和基于多轮问答的抽取流程有机地结合在一起。
2.  **知识图谱对大模型的双重赋能机制**：创造性地利用知识图谱实现了对大语言模型的双重增强：
    * **微调阶段**：利用知识图谱的三元组生成高质量的指令数据集，通过LoRA对模型进行领域适配。
    * **推理阶段**：基于思维记忆（MOT）机制，在提示中动态注入从知识图谱中检索到的高置信度问答样例，实现有效的上下文学习。
3.  **支持迭代与小样本应用的潜力**：该框架支持通过循环迭代的方式提升知识抽取的整体效果（抽取结果可用于完善知识图谱）。同时，在标注数据不足时，可不进行微调，直接基于领域本体和大语言模型实现小样本乃至零样本的知识抽取，具有较好的灵活性和可移植性。

=============================《文章分隔符》=============================

 # 基于创新知识元谱系的学术论文新颖性测度研究 (2024年1月)

### 1. 研究目标 · 内容 · 问题 · 出发点
- **研究领域与背景、具体对象 / 数据集**
    - **研究领域与背景**：本研究属于学术评价领域，具体聚焦于学术论文新颖性的量化测度。背景是当前主流的基于“频次”和“引文”的评价方法，本质上衡量的是论文的“影响力”而非“创新性”，两者并不完全对等。因此，研究提出需要从论文的语义内容层面探索一种新的创新性评价思路。
    - **具体对象 / 数据集**：研究以学术论文为评价对象。在实证分析部分，研究以“图书馆学研究对象”为主题，采集了中国知网（CNKI）自1949年至2023年5月的151篇相关论文，经过人工筛选，最终精炼出50篇核心理论文献作为分析数据集。

- **论文想解决的核心问题**
    - 核心问题是如何摆脱传统评价指标的局限，从学术论文的内在语义内容出发，建立一套能够客观、量化测度其新颖性的模型和方法。这包含两个关键子问题：一是如何构建一个能够反映学科知识演进脉络的评价参照系（即“创新知识元谱系”）；二是如何基于该参照系，设计一个有效的新颖性测度模型。

- **研究动机 / 假设**
    - **研究动机**：帮助科研人员在海量文献中快速识别出真正具有创新性的成果，节省其知识发现和筛选的时间。同时，为学术评价体系提供一种更侧重于内容创新的新视角和新工具。
    - **研究假设**：一篇学术论文的创新性体现在其所包含的“创新知识元”上。通过构建一个特定主题领域的“创新知识元谱系”，可以将待测论文的知识元与谱系进行语义比对，通过其在谱系中的位置和与已有知识元的关系，来定量地测度其新颖程度。

- **工作内容概览**
    - **引言与相关研究**：指出当前学术评价方法的不足，引出基于内容和语义进行新颖性测度的必要性，并回顾了基于文本特征和知识图谱的两种现有方法及其局限。
    - **创新知识元谱系构建**：提出了“创新知识元谱系”的核心概念，设计了其包含“创新对象-主题对象-主题域-问题链”的四层概念模型，并定义了谱系中节点间的创新关系（如原始创新、累积创新等）。
    - **新颖性测度模型**：构建了一个完整的新颖性测度流程模型，包括知识元抽取、语义标注、谱系定位、关系判定和新颖度计算。并提出了一个用于量化计算相对新颖度的数学函数。
    - **实证分析**：以“图书馆学研究对象”为案例，详细展示了从数据采集、知识元标注、谱系构建到对20篇具体论文进行新颖性测度与评判的全过程。
    - **模型评价与结论**：总结了该测度模型基于分类比较、借助学术谱系、针对内容评价的特点，并指出了其在谱系构建上存在人工干预较多和适用领域有限的局限性。

### 2. 研究方法（含模型 / 技术详解）
- **理论框架与算法**
    - 本研究的理论框架是“数据驱动的学术评价范式”，其核心思想是：将学术论文内容进行结构化和语义化（抽取“创新知识元”），然后将其与一个形式化的、反映学科知识演进的参照系（“创新知识元谱系”）进行比对，从而输出对论文创新性的评价结果。该框架强调“先分类，再比较”的评价原则。

- **关键模型/技术逐一说明**
    - **1. 创新知识元谱系 (Innovative Knowledge Element Genealogy)**
        - **架构**：一个以“创新知识元”为节点、以知识元间的创新演化关系为边的网络图谱。其概念模型分为四个层级，自顶向下进行分类：
            1.  **创新对象**：对创新的顶层分类，如问题创新、理论创新、方法创新等。
            2.  **主题对象**：研究的具体客体。
            3.  **主题域**：研究客体的具体方面或属性。
            4.  **问题链**：围绕特定主题域形成的一系列有逻辑关联的研究问题，直接关联到具体的知识元实例。
        - **流程**：构建过程主要依赖人工和专家知识。首先通过文献梳理，确定领域内的关键创新观点作为节点，然后依据学术史和逻辑关系判断节点间的创新类型（如继承、演进、突破等），从而连接成谱系网络。
        - **优势**：为新颖性评价提供了一个统一、可视、可比较的语义参照系，减少了同行评议的主观性和认知局限。
        - **局限**：谱系具有高度的领域特定性，无法跨领域通用。其构建过程复杂，需要大量人工干预和深厚的领域知识，难以大规模自动化。

    - **2. 新颖性测度模型 (Novelty Measurement Model)**
        - **架构**：一个多步骤的流水线模型。
        - **输入**：待评测的学术论文。
        - **输出**：该论文核心创新知识元的量化新颖度得分。
        - **推理流程**：
            1.  **知识元抽取与标注**：从待评测论文中，通过规则（如“A是B”等定义性句式）或模型抽取出表达核心观点的“创新知识元”语句，并将其标注为`S(主体)-P(谓词)-O(客体)`的语义三元组。
            2.  **谱系定位与匹配**：根据知识元的语义内容，将其在已构建的“创新知识元谱系”中进行定位，找到其所属的“问题链”。
            3.  **关系判定**：将待测知识元与问题链中的已有知识元进行语义比对。若谱系中无匹配节点，则判定为“原始创新”。若有，则依据领域语义词典（如本体）中概念的层级关系，判定两者是“相近关系”（继承创新）、“相关关系”（演进创新）还是“相异关系”（突破创新）。
            4.  **新颖度计算**：根据判定的关系类型和预设的权重值，代入新颖性测度函数，计算出最终的新颖度得分。

- **重要公式**
    - 论文提出了一个**相对新颖度 (Relative Novelty)** 的计算函数：
    $$Nov(KE)=\sigma\frac{P\prod_{i=1}^{t}S_{i}}{P+P\sum_{i=1}^{t}S_{i}}$$
    - 其中：
        - $Nov(KE)$ 是待测知识元的相对新颖度。
        - $P$ 是问题链源头（原始创新）的初始新颖度值，代表绝对新颖度。
        - $S_i$ 是创新链上第 $i$ 个知识元的语义关系权重。
        - $P$ 和 $S_i$ 的取值参考一个预定义的“新颖性测度指标体系”表，该表根据“创新类型”（如问题发现类、理论构建类）和“创新方式”（如整体原创、演进创新、继承创新）给出了0到1之间的权重赋值。
        - 分子 $P\prod_{i=1}^{t}S_{i}$ 代表当前知识元的绝对新颖度。
        - 分母是创新链上所有先前知识元绝对新颖度的累加和。
        - $\sigma$ 是一个可忽略的新颖性系数。

### 3. 实验设计与结果（含创新点验证）
- **实验流程**
    1.  **数据准备**：选定“图书馆学研究对象”为实证领域，从CNKI采集151篇论文，经人工清洗和筛选，得到50篇核心理论文献。
    2.  **知识元标注**：通过人工阅读和总结，制定了针对“图书馆学研究对象是什么”这类观点的抽取规则（如“图书馆学研究对象是……”）。利用这些规则从50篇文献中抽取关键语句，并将其标注为语义三元组。
    3.  **谱系构建**：参考《中国图书馆学科发展史》及相关综述，选取领域内的代表性观点作为知识元节点。以“图书馆说”、“情报交流说”等为根节点（原始创新），根据各学说间的思想传承和演化关系，构建了一个包含4个主干和16个分支的“图书馆学研究对象”创新知识元谱系。此过程经专家审定。
    4.  **新颖性测度**：从数据集中选取20篇论文进行新颖性计算。对每篇论文的知识元，首先在谱系中定位，然后判定其与父节点的关系（原始、继承、演进等），最后根据指标表中的权重代入公式计算新颖度。

- **数据集、参数、评价指标**
    - **数据集**：50篇关于“图书馆学研究对象”的CNKI核心理论文献（1949-2023年）。
    - **参数**：参数主要来自“新颖性测度指标体系”（表3）。该表为不同创新类型（如理论构建类）和创新方式（如整体原创、继承创新）的组合预设了权重。例如，“整体原创”的权重为1.0，“演进创新”为0.3，“继承创新”为0.1。
    - **评价指标**：最终的评价指标是公式计算出的“相对新颖度”($Nov(KE)$)得分。

- **创新点如何得到验证，结果对比与可视化描述**
    - **验证方式**：通过案例分析来验证模型的合理性。例如：
        - **案例1（原始创新）**：一篇1986年的论文提出“文献信息的开发与利用”是研究对象。由于在当时构建的谱系中找不到可匹配的先驱节点，该观点被判定为“观点创新”（一种原始创新），获得较高的新颖度0.6。
        - **案例2（继承创新）**：一篇2006年的论文提出“文献信息保障”是研究对象。在语义上，“文献信息保障”与“文献信息的开发与利用”同属一类，因此被判定为“继承”关系，其新颖度计算后仅为0.0353，远低于前者。
        - **案例3（重复创新）**：一篇2009年的论文观点与王子舟先生的“知识集合论”相重复，因此被判定为无新颖性，得分为0。
    - **结果对比与可视化**：
        - **对比**：实验结果以表格形式（表6）呈现，清晰列出了20个知识元（论文观点）、判定的创新类型、计算出的新颖度得分和发表年份，方便横向对比。
        - **可视化**：研究的核心成果“图书馆学研究对象创新知识元谱系”以网络图（图5）的形式呈现。图中，每个节点代表一个学说观点，边代表它们之间的演化关系（继承、演进等），并且每个节点都标注了计算出的新颖度值，直观地展示了该领域知识的演进脉络和各观点的创新程度。

- **主要实验结论与作者解释**
    - 实验结果表明，该模型能够借助创新知识元谱系作为参照，从语义内容层面有效地区分不同类型的创新，并给出量化的新颖性测度。
    - 作者解释，计算出的新颖度值是论文发表时相对于当时已有知识的“即时新颖性”，高新颖性不完全等同于高影响力或高质量，但它揭示了该研究在知识发展脉络中的位置和贡献，具有重要的科研价值。

### 4. 研究结论
- **重要发现**
    - **定性**：本研究成功构建了一套基于“创新知识元谱系”的学术论文新颖性测度理论框架和模型。该模型的核心优势在于建立了明确的、形式化的评价参照系，并遵循“先分类再比较”的原则，实现了对论文核心思想的直接评价。
    - **定量**：提出了一个可计算的相对新颖度函数，并通过实证分析验证了其可行性。计算结果能够量化地区分原始创新、演进创新和继承创新等不同程度的创新。

- **对学术或应用的意义**
    - **对学术**：为学术评价领域提供了一种超越传统计量指标的新范式，推动评价体系向更注重实质性内容创新的方向发展。通过提供统一的参照系，有助于降低同行评议的主观性，使评价更加公平和透明。
    - **对应用**：可以开发成工具，帮助研究者在海量文献中快速发现前沿和突破性成果。同时，能够用于动态监测特定学科领域的知识演进趋势和创新热点，为科研管理和政策制定提供决策支持。

### 5. 创新点列表
- **提出以“创新知识元谱系”为参照系的评价思想**：首次将学术谱系思想形式化、模型化，并将其作为测度论文内容新颖性的核心参照标准。
- **构建了创新知识元谱系的概念模型**：系统地设计了谱系的“创新对象-主题对象-主题域-问题链”四层结构，为构建和理解谱系提供了理论框架。
- **设计了完整的新颖性测度模型与流程**：提出了一套从知识元抽取、语义比对、关系判定到量化计算的完整、可操作的测度流程。
- **创建了新颖性量化计算函数**：将定性的创新类型（原始、累积）与定量的数学函数相结合，实现了对新颖度的数值计算。
- **强调“先分类再比较”的评价原则**：将待测知识元置于其所属的特定问题谱系中进行比较，而非泛泛而谈，保证了比较的公平性和针对性。

=============================《文章分隔符》=============================

 # 分类评价视角下学者研究优势识别与评价研究——基于Z指数的研究 (2025-06-19)

### 1. 研究目标 · 内容 · 问题 · 出发点

- **研究领域与背景、具体对象 / 数据集**
  - **研究领域**：科技人才评价，信息计量学。
  - **背景**：在中国推动科技人才评价机制改革，旨在破除“唯论文、唯职称、唯学历、唯奖项、唯帽子”的“五唯”倾向，建立科学分类、多元综合的评价体系。
  - **具体对象**：以中国信息资源管理领域为实证场景，研究对象为2019-2023年间，在20本CSSCI核心期刊上以第一作者身份发文量排名前50位的高产学者。
  - **数据集**：源自CNKI数据库，首先筛选出18,461篇论文以确定50位高产学者，然后针对这50位学者收集其五年内发表的全部论文，经过去重和筛选（如剔除“序言”等非学术论文），最终形成一个包含2921条论文数据的分析集。

- **论文想解决的核心问题**
  现有学术评价指标（如h指数）虽然能衡量学者的综合影响力，但难以细致地识别学者在特定细分研究方向上的贡献和优势，尤其对从事小规模或新兴主题研究的优秀学者可能存在评价偏差和埋没的风险。

- **研究动机 / 假设**
  - **动机**：为响应国家科技体制改革中对人才进行分类评价的需求，构建一种更科学、客观、公平的学者评价方法，以实现对学者研究优势的细粒度识别。
  - **假设**：通过将研究主题分类与学者贡献度量化相结合，并融入改进的文献计量学指标（z指数），可以更准确地识别出学者在不同研究方向上的真实影响力，从而发现那些在特定领域（包括新兴或小众领域）做出重要贡献的人才。

- **工作内容概览**
  1.  **模型构建**：首先，提出通过关键词聚类来划分学科领域内的研究主题；其次，构建“主题—学者—被引”三维关系数据；最后，在传统z指数的基础上，引入“篇均关键词权重”和“作者合著权重”，设计了改进的ZAK指数评价模型。
  2.  **数据准备与基准分析**：以信息资源管理领域的50位高产学者为例，收集其论文数据，并计算传统的h指数、p指数和z指数，通过相关性和离散度分析，验证z指数作为基准的优越性。
  3.  **主题划分与实证分析**：利用Word2Vec和K-means算法对学者论文的关键词进行聚类，划分出13个研究主题。
  4.  **结果评估与验证**：计算每位学者在13个主题下的ZAK指数，并通过热力图进行可视化。通过横向（跨学者）和纵向（跨主题）对比，验证ZAK指数在识别特定领域杰出人才、发现新兴/小众领域优秀学者方面的有效性。

### 2. 研究方法（含模型 / 技术详解）

- **理论框架与算法**
  本研究的理论框架建立在文献计量学的基础上，核心是**对z指数进行改进和应用**。整个流程分为两大部分：
  1.  **研究主题划分**：采用非监督机器学习方法，通过**Word2Vec词嵌入**和**K-means聚类算法**对论文关键词进行主题聚类。
  2.  **影响力评价**：构建一个**改进的ZAK指数模型**，该模型在z指数的基础上融入了**篇均关键词权重**和**作者合著贡献权重**，以实现基于主题分类的、更公平的学者影响力评价。

- **关键模型/技术逐一说明**
  1.  **研究主题划分 (Word2Vec + K-means)**
      - **架构**：首先使用Word2Vec的Skip-gram模型将关键词转换为高维向量，捕捉其语义关系。然后，使用K-means算法对这些词向量进行聚类，将语义相近的关键词划分到同一簇中，每一个簇即代表一个研究主题。
      - **输入**：特定学科领域内所有目标学者论文的关键词集合。
      - **流程**：
          1.  提取全部论文的关键词。
          2.  使用Word2Vec训练词向量。
          3.  通过轮廓系数（Silhouette Coefficient）等指标确定最优聚类数K。
          4.  运行K-means算法，将关键词向量划分为K个主题簇。
          5.  人工对聚类结果进行校验和命名，提升主题划分的准确性。
      - **优势**：能够基于数据驱动的方式客观地揭示学科内的研究主题结构。
      - **局限**：聚类结果依赖于算法和参数选择，且可能无法完全捕捉语义的细微差异，需要人工干预修正。

  2.  **改进的ZAK指数模型**
      - **架构**：该模型的核心是对原始z指数进行加权改进。z指数本身综合了产出数量(n)、总影响力(C)和影响力分布(被引平方和)，而ZAK指数在此基础上，对每一次被引(C)进行加权，权重由“篇均关键词权重”和“作者贡献权重”共同决定。
      - **输入**：对于一位特定学者在特定主题下的评价，需要输入：
          - 该主题下的论文数 (P)
          - 这些论文中的关键词总数 (X)
          - 每篇论文的作者总数 (a) 和该学者的署名次序 (j)
          - 每篇论文的被引频次 (Cᵢ)
      - **流程**：
          1.  **计算篇均关键词权重(S)**：旨在平衡关键词数量的影响，避免通过堆砌关键词获得不公平优势。
          2.  **计算作者贡献权重(Wⱼ)**：根据作者署名次序分配贡献度。
          3.  **计算单篇论文的加权被引(Cₖᵢ)**：将原始被引频次与上述两个权重相乘。
          4.  **计算ZAK指数**：将加权后的被引数据代入z指数的计算框架。
      - **优势**：
          - 通过主题分类，实现了对学者在不同领域贡献的区分评价。
          - 通过引入篇均关键词权重，抑制了对发文数量和关键词堆砌的过度依赖。
          - 通过作者贡献权重，更公平地反映了学者在合作研究中的实际贡献。
      - **局限**：权重的设计（如作者贡献的递减公式）仍是一种简化，可能无法完全反映复杂的合作现实。

- **重要公式**
  1.  **篇均关键词权重 (S)**：
      $$S=10\times\frac{P}{X}$$
      其中, P为学者在某个主题中发表的论文数，X为这些论文中的关键词总数。

  2.  **作者贡献权重 (Wⱼ)**：
      $$W_{j}=\frac{a-j+1}{\Sigma_{j=1}^{a}j}$$
      其中, a为一篇论文的作者总数，j为目标学者的署名次序。

  3.  **单篇论文加权被引 (Cₖᵢ)**：
      $$C_{Ki}=\frac{10P}{X}*\frac{a_{i}-j_{i}+1}{\Sigma_{j_{i}=1}^{a_{i}}j_{i}}*C_{i}$$
      该公式综合了篇均关键词权重、作者贡献权重与原始被引频次(Cᵢ)。

  4.  **最终ZAK指数 (ZAK)**：
      $$ZAK = [\frac{(\Sigma_{i=1}^{X}C_{Ki})^{4}}{X^{2}\Sigma_{i=1}^{X}C_{Ki}^{2}}]^{\frac{1}{3}}$$
      其中，X是学者在主题K下的关键词总数（作为评价单元的数量），Cₖᵢ是每个关键词所属论文的加权被引。

### 3. 实验设计与结果（含创新点验证）

- **实验 / 仿真 / 原型流程**
  1.  **数据采集**：从CNKI中检索信息资源管理领域的20本CSSCI期刊在2019-2023年的全部论文，确定发文量前50的第一作者。再反向检索这50位学者在此期间发表的所有论文，清洗后得到2921篇作为最终数据集。
  2.  **基准指标计算**：为50位学者计算h指数、p指数、z指数，并进行相关性分析（Pearson和Spearman）和离散度评估（变异系数CV）。
  3.  **研究主题划分**：
      - 提取2921篇论文中的全部12813个关键词（6346个独立词）。
      - 使用Word2Vec (Skip-gram, 100维, 窗口5, 最小词频1) 训练词向量。
      - 计算轮廓系数，确定最优聚类数K=13。
      - 使用K-means对词向量聚类，得到13个主题的初步划分。
      - 邀请3位领域专家进行人工校对和主题命名，确保分类的准确性。
  4.  **ZAK指数计算与可视化**：
      - 对每位学者，将其论文按所属主题分类。
      - 在每个主题内部，根据公式计算该学者的ZAK指数。
      - 将50位学者在13个主题上的ZAK指数结果绘制成一个热力图，进行可视化分析。

- **数据集、参数、评价指标**
  - **数据集**：50位信息资源管理领域高产学者在2019-2023年发表的2921篇论文及其元数据（关键词、作者、被引频次等）。
  - **参数**：
      - Word2Vec: 向量维度=100，上下文窗口=5，最小词频=1。
      - K-means: 聚类数K=13。
  - **评价指标**：
      - **基准指标**：h指数、p指数、z指数。
      - **模型指标**：轮廓系数 (用于确定K值)。
      - **核心评价指标**：改进的ZAK指数。

- **创新点如何得到验证，结果对比与可视化描述**
  1.  **验证z指数作为基准的合理性**：
      - **结果对比**：相关性分析显示，h、p、z三种指数高度正相关（如p指数和z指数的皮尔逊相关性为0.949），说明它们在衡量学术影响力上具有内在一致性。离散度评估显示，z指数的变异系数最高（30.03%），表明其对学者影响力的区分度更优。
      - **可视化**：图2的散点图直观展示了三种指数的分布趋势，z指数的散点分布适中，兼具区分度与稳定性。
  2.  **验证ZAK指数识别特定/新兴领域专家的能力**：
      - **结果对比与可视化**：表4的热力图是核心验证工具。
          - **案例1 (识别特定领域人才)**：学者吴丹的综合指数（h, p, z）排名均未进入前20，但在热力图中，其在“信息素养研究”主题下的ZAK指数排名第二，颜色块呈深红色。这验证了ZAK能发现被传统综合指标“低估”的领域专家。
          - **案例2 (识别新兴领域人才)**：学者王文韬的综合排名居中，但在新兴主题“突发事件与网络舆情”中的ZAK指数高居第一，显著超过其他学者。
          - **案例3 (识别小众领域人才)**：学者张靖的综合排名在50人中处于末位，但在小众方向“古籍管理与保护”上有较高的ZAK指数，证明了模型对小规模研究方向贡献的识别能力。
  3.  **验证ZAK指数的分类评价与多维视角能力**：
      - **结果对比与可视化**：热力图的横向分析揭示了学者的研究画像。
          - **案例 (学者研究结构分析)**：学者王晰巍在“信息行为与用户画像”、“知识发现”、“突发事件”等8个主题中均有很高的ZAK指数值（深红色块分布广泛），体现了其研究的广度和交叉能力。这验证了该方法能帮助学者了解自身研究结构和优势方向。

- **主要实验结论与作者解释**
  - ZAK指数与传统指标在宏观上保持一致性，但通过引入主题分类和权重调整，显著提升了评价的区分度和公平性。
  - 该模型能够有效识别在特定、小众或新兴研究方向上做出突出贡献的学者，而这些学者在传统综合性评价中可能并不突出。
  - ZAK指数不仅可以用于人才评价，还可以帮助学者进行自我定位，发现优势研究方向，并促进学科内部的知识交叉与合作。

### 4. 研究结论

- **重要发现（定量 / 定性）**
  1.  **定量发现**：在传统指标中，z指数相较于h指数和p指数具有最高的变异系数(30.03%)，能更好地对学者进行区分。
  2.  **定性发现**：
      - 本文提出的ZAK指数模型能够成功识别出在特定研究主题（如“信息素养研究”、“突发事件与网络舆情”）中具有顶尖影响力的学者，即使他们的综合排名不高。
      - 该模型能够发掘在小规模（如“古籍管理与保护”）或新兴研究领域的优秀学者，为他们提供了公平的评价视角。
      - 通过分析学者在不同主题下的ZAK指数分布，可以揭示其研究的广度与深度，识别出如王晰巍一样的跨领域通才型学者。

- **对学术或应用的意义**
  - **学术意义**：为学者评价理论体系提供了新的视角和方法论参考，推动了学术评价从单一量化指标向“分类化、多元化”的细粒度评估转变，完善了z指数的应用场景。
  - **应用意义**：
      - 为高校和科研机构的人才引进、职称评定和资源配置提供了更科学、公正的决策支持工具。
      - 能够帮助学者（尤其是青年学者）清晰定位自身研究优势，规划未来研究方向。
      - 有助于促进不同研究方向学者之间的精准合作与知识交流，推动学科的整体创新与发展。

### 5. 创新点列表

- **1. 提出融合主题分类的学者评价新框架**：构建了“主题—学者—被引”三维分析框架，将学者评价从宏观综合层面下沉到中观的细分研究主题层面，实现了分类评价。
- **2. 创新性地改进z指数模型**：首次将“篇均关键词权重”和“作者合著贡献权重”两个关键调节因子引入z指数，设计出新的ZAK指数，有效解决了传统指标过度依赖发文量和无法公平体现合作贡献的问题。
- **3. 实现了对小众及新兴领域优秀学者的有效识别**：通过实证分析证明，该方法能够发现在传统评价体系中容易被忽视的、但在特定小众或新兴研究方向上做出重要贡献的学者，体现了评价的公平性和前瞻性。
- **4. 提供了多维度的学者研究画像**：该方法不仅能评价学者在某一主题的“高度”，还能通过分析其在所有主题的ZAK指数分布，揭示其研究的“宽度”和交叉能力，为学者自我认知和学术合作提供了新工具。

=============================《文章分隔符》=============================

 # 以引用句为桥的知识跨学科输出影响力分析——以信息资源管理学科为例 (2025年3月)

### 1. 研究目标 · 内容 · 问题 · 出发点
- **研究领域与背景、具体对象 / 数据集**
  - **研究领域与背景**：本研究位于学科交叉融合与科学计量学领域。背景是，随着科技发展，学科间知识渗透与融合成为常态，因此分析一个学科的知识输出及其对其他学科的影响力，对于明确学科定位、提升学术话语权至关重要。
  - **具体对象**：以“信息资源管理”学科作为实证分析的目标学科。
  - **数据集**：选取了12种信息资源管理领域的CSSCI核心期刊在2017-2022年间发表的8392篇文献，以及在中国知网（CNKI）中国引文数据库中找到的、引用了这些文献的12632篇跨学科学术论文。

- **论文想解决的核心问题**
  传统基于被引频次的学科影响力评价方法粒度过粗，无法细致地揭示目标学科的特定知识（如一个理论或方法）与所影响的其他学科知识之间的内在联系及刺激创新的具体程度。核心问题是如何构建一个能够细粒度、一对一地测度“目标学科的某个知识点”对“另一学科的某个知识点”创新影响力的模型。

- **研究动机 / 假设**
  研究的出发点是，跨学科施引文献中的“引用句”是连接输出知识与接收知识的关键“桥梁”。论文假设：
  1.  引用句的**语义**可以反映输出知识与接收知识的关联密切程度。
  2.  引用句在论文中的**位置**（如方法、引言）和作者表达的**情感**（如正面、中性引用）可以反映输出知识对接收方知识创新的刺激效率与价值。
  基于此，可以通过分析引用句来更精确地量化知识影响力。

- **工作内容概览（精炼概述各章节核心）**
  - **引言与相关研究**：指出当前学科影响力研究多依赖被引频次，缺乏细粒度分析，并提出以引用句为桥梁的研究思路。
  - **研究思路与模型构建**：详细阐述了研究的理论框架，从“知识关联度”和“知识创新效率”两个维度出发，构建了衡量具体知识点之间影响力的数学模型。
  - **实证分析**：以信息资源管理学科为例，详细描述了从数据采集、预处理（如跨学科文献界定、引用句提取）、指标计算（如使用Sentence-BERT计算语义相似度）到应用模型的全过程。
  - **结果分析与讨论**：展示了计算出的学科核心知识与交叉知识的影响力排名，验证了模型的有效性，并深入分析了信息资源管理学科知识影响力的特征、来源与去向。
  - **结语**：总结了研究的核心发现与模型贡献，并指出了未来研究方向，如将模型应用于更广泛的学科领域。

### 2. 研究方法（含模型 / 技术详解）
- **理论框架与算法**
  本研究的理论框架认为，目标学科知识 $\gamma$ 对跨学科知识 $\beta_j$ 的影响力（$KIM$）是**知识关联度**（$KR$）和**知识创新效率**（$KU$）的乘积。
  - **知识关联度 ($KR$)**：通过计算知识 $\gamma$、知识 $\beta_j$ 与连接它们的引用句之间的语义相似度来衡量。关联度越高，表明知识 $\gamma$ 为创新输出转化提供的资源支持越多。
  - **知识创新效率 ($KU$)**：通过分析引用句在施引文献中的位置和情感来衡量。例如，出现在“方法”部分的正面引用，比出现在“引言”部分的中性引用具有更高的创新刺激效率。

- **关键模型/技术逐一说明：架构、输入输出、训练或推理流程、优势与局限**
  - **技术1：语义相似度计算 (Sentence-BERT)**
    - **架构**：采用基于Sentence-BERT算法的`paraphrase-multilingual-MiniLM-L12-v2`多语言预训练模型。该模型能将句子和关键词映射为高维语义向量。
    - **输入**：目标学科关键词 $\gamma$、跨学科关键词 $\beta_j$、以及它们之间的跨学科施引文献引用句 $i$。
    - **推理流程**：将输入的文本（关键词、引用句）送入模型，输出其对应的语义向量。然后通过余弦相似度公式计算关键词向量与引用句向量之间的相似度得分，即 $sim(\gamma, i)$ 和 $sim(\beta_j, i)$。
    - **优势**：能捕捉深层次的语义信息，远优于简单的文本匹配。

  - **模型1：知识关联度 ($KR$) 模型**
    - **架构**：该模型综合了每次引用（共 $n$ 次）中知识 $\gamma$ 和 $\beta_j$ 与引用句的语义相似度。它将两个相似度的乘积作为基础关联，并用两者之差的绝对值进行调整，以体现关联的一致性（两个相似度越接近，关联越稳定）。
    - **输入**：知识 $\gamma$ 与引用句的相似度 $sim(\gamma, i)$，知识 $\beta_j$ 与引用句的相似度 $sim(\beta_j, i)$，以及总引用次数 $n$。
    - **输出**：知识 $\gamma$ 和 $\beta_j$ 之间的总关联度 $KR(\gamma, \beta_j)$。

  - **模型2：知识创新效率 ($KU$) 模型**
    - **架构**：计算所有 $n$ 次引用对知识创新刺激效率的平均值。每次引用的效率由其所在位置的权重和情感权重相乘得到。
    - **输入**：每次引用的位置权重 $P(x)_i$ 和情感权重 $E(y)_i$，以及总引用次数 $n$。这些权重由领域专家打分并经过信度检验（Cronbach's $\alpha$）后确定。
    - **输出**：知识 $\gamma$ 对 $\beta_j$ 的平均创新刺激效率 $KU(\gamma, \beta_j)$。

  - **模型3：知识影响力模型 ($KIM$)**
    - **架构**：最终的影响力模型，将知识关联度与知识创新效率相乘，得到一个综合性的影响力得分。
    - **输入**：计算出的 $KR(\gamma, \beta_j)$ 和 $KU(\gamma, \beta_j)$。
    - **输出**：知识 $\gamma$ 对知识 $\beta_j$ 的影响力 $KIM(\gamma, \beta_j)$。一个知识 $\gamma$ 的总体影响力是其对所有不同跨学科知识影响力之和。

- **重要公式（如有）**
  - **知识关联度 ($KR$)**：
    $$KR(\gamma,\beta_{j})=\sum_{i=1}^{n}\left[\frac{sim(\gamma,i) \cdot sim(\beta_{j},i)}{|sim(\gamma,i)-sim(\beta_{j},i)|+1}\right]$$
  - **知识创新效率 ($KU$)**：
    $$KU(\gamma,\beta_{j})=\frac{\sum_{i=1}^{n}P(x)_{i} \cdot E(y)_{i}}{n}$$
  - **知识影响力 ($KIM$)**：
    $$KIM(\gamma,\beta_{j})=KR(\gamma,\beta_{j}) \cdot KU(\gamma,\beta_{j})$$
  - **知识总体影响力**：
    $$KIM(\gamma,\beta)=\sum_{j=1}^{J}KIM(\gamma,\beta_{j})$$

### 3. 实验设计与结果（含创新点验证）
- **实验 / 仿真 / 原型流程**
  1.  **数据采集与筛选**：从CNKI数据库中，获取12种信息资源管理期刊在2017-2022年的载文及所有施引文献。
  2.  **跨学科文献界定**：依据科学引文数据库（SCD）的学科分类标准，对施引文献按其发表期刊进行学科归属划分。非本学科的施引文献被界定为跨学科施引文献，并下载全文。
  3.  **引用句提取**：使用Python正则表达式，在跨学科施引文献全文中定位对样本文献的引用，并自动提取该引用标记前后的完整句子。最后进行人工核对与清洗。
  4.  **关键词与相似度计算**：提取目标文献的关键词 $\gamma$ 和跨学科施引文献的关键词 $\beta_j$。使用Sentence-BERT模型计算每个引用句与两边关键词的语义相似度。
  5.  **位置与情感权重赋值**：
      - **位置**：通过正则匹配章节标题，将引用句归类到“引言”、“综述”、“方法与实验”、“结果与讨论”、“结语”五类之一。
      - **情感**：人工标注30%的引用句情感（正面、中性、负面）以构建情感词典，再对剩余70%进行自动分类，并人工审核。
      - 根据预设的权重表为每个引用句赋予位置权重 $P(x)$ 和情感权重 $E(y)$。
  6.  **影响力计算**：将上述所有数据代入KR、KU、KIM公式，计算出每个信息资源管理知识点对每个跨学科知识点的影响力，并汇总得到总体影响力。

- **数据集、参数、评价指标**
  - **数据集**：如前述，源自CNKI的12种期刊5年份的8392篇论文及其12632篇跨学科施引文献。
  - **参数**：
    - **位置权重**：方法与实验 (0.383) > 结果与讨论 (0.272) > 综述 (0.120) > 结语 (0.118) > 引言 (0.107)。
    - **情感权重**：正面引用 (0.632) > 中性引用 (0.232) > 负面引用 (0.136)。
  - **评价指标**：论文提出的 $KR(\gamma, \beta_j)$, $KU(\gamma, \beta_j)$, $KIM(\gamma, \beta_j)$ 及总体影响力 $KIM(\gamma)$。

- **创新点如何得到验证，结果对比与可视化描述**
  - **创新点验证**：本研究的创新在于细粒度分析。作者通过一个具体案例进行说明：对比“信息计量”对“知识图谱”的影响和“引文分析”对“研究热点”的影响。两者的最终影响力KIM值相近（17.38 vs 17.46），但成因完全不同：
    - 前者是高关联度（KR=3.41）和中等创新效率（KU=5.16），表现为知识传承。
    - 后者是低关联度（KR=1.93）和极高创新效率（KU=9.07），表现为方法支撑和创新刺激。
    这种深度的差异化分析是传统方法无法实现的，从而验证了本模型的优越性。
  - **结果对比**：将本研究识别出的高影响力知识（如网络舆情、知识图谱）和主要影响的学科（管理科学与工程、计算机科学与技术）与该领域已有的宏观研究成果对比，发现结果有一致性，从而间接验证了模型的有效性。
  - **可视化描述**：通过两个核心表格（表4和表5），以降序方式清晰展示了“专业核心知识”和“交叉知识”的总体影响力排名、它们具体影响了哪些跨学科知识、以及对应的频次、KR、KU、KIM值和受影响学科的分布。

- **主要实验结论与作者解释**
  - **结论1**：信息资源管理学科主要影响社会科学（特别是管理科学与工程）的知识创新，对自然科学影响较小。
  - **结论2**：成熟的交叉知识（如网络舆情、大数据）对外输出影响力远强于专业核心知识（如信息计量、专利分析）。
  - **结论3**：该学科的知识输出主要影响其他学科中相近的交叉研究领域，很难影响到其他学科的专业核心知识创新。
  - **作者解释**：作者认为，专业核心知识影响力较弱，可能是因为其本身复杂性高，导致外部学科难以快速消化吸收；也可能是研究者更倾向于追逐热门的交叉领域。作者强调，专业核心知识是学科安身立命之本，需要得到更多的传承与创新，以塑造学科真正的“内生”影响力。

### 4. 研究结论
- **重要发现（定量 / 定性）**
  1.  **定量**：信息资源管理学科的交叉知识影响力巨大，排名前二的“网络舆情”和“大数据”总体影响力值（KIM）分别高达2197.75和2120.70；而专业核心知识排名第一的“信息计量”影响力仅为913.65。
  2.  **定性**：该学科的影响力呈现出典型的“内循环”特征，即其知识（无论是核心还是交叉）主要流向并影响其他学科的交叉研究领域，而难以穿透壁垒，对其他学科的核心知识体系产生实质性影响。影响力强的知识多为成熟的、与其他学科共有的交叉知识。

- **对学术或应用的意义**
  - **学术意义**：提出了一种全新的、基于引文内容和上下文的细粒度知识影响力测度模型。该模型超越了传统的引文计数，能够揭示知识传播背后更深层次的关联与创新刺激机制，为科学计量学和学科发展研究提供了新工具和新视角。
  - **应用意义**：该模型可以作为一种“学科诊断”工具。学科建设者可以利用它来精确评估本学科不同知识板块的对外影响力来源（哪些知识贡献大）和去向（影响了谁），从而发现优势、弥补短板，有针对性地调整学科发展战略，特别是加强核心知识的创新与推广。

### 5. 创新点列表
- **1. 提出全新的双维影响力模型**：摒弃单一的被引频次，创新性地从“知识关联度”和“知识创新效率”两个维度构建了知识影响力测度模型。
- **2. 实现细粒度的影响力分析**：以引用句为分析桥梁，结合自然语言处理技术（Sentence-BERT），能够深入分析具体知识点之间的影响强度与影响模式（是知识传承还是创新激发）。
- **3. 提供全面的影响力图景**：模型不仅能识别目标学科“输出了什么”，还能清晰地揭示这些知识“影响了谁的什么知识”以及影响程度，实现了对知识影响力来源和去向的全方位、穿透式把握。
- **4. 构建了可复现的实证流程**：详细阐述了从数据获取、处理到模型计算的完整技术路径，为其他学科应用该模型进行自我评估提供了清晰的范例。

=============================《文章分隔符》=============================

 # SubTST: A Combination of Sub-word Latent Topics and Sentence Transformer for Semantic Similarity Detection (2022)

### 1. 研究目标 · 内容 · 问题 · 出发点
- **研究领域与背景、具体对象 / 数据集**
    - **研究领域**: 自然语言理解 (NLU) 中的语义文本相似度检测 (Semantic Textual Similarity, STS)。
    - **背景**: STS 旨在判断两个句子的语义关联性，是信息检索、释义检测等任务的基础。现有方法中，SBERT 通过结合预训练的 BERT 和孪生网络（Bi-encoder）取得了显著效果；tBERT 则通过将主题嵌入与 BERT 输出拼接（Cross-encoder），证明了主题信息的有效性。
    - **具体对象 / 数据集**: 论文使用了三个基准数据集进行评估：Quora（问题对）、MSRP（新闻句子对）和 SemEval CQA（社区问答对）。

- **论文想解决的核心问题**
    - 如何更有效地将主题模型 (Topic Model) 的信息与基于 Transformer 的模型（如 BERT）相结合，以提升语义相似度检测的性能。
    - 如何解决传统主题模型（基于词或文档）与 Transformer 模型（基于子词）在基本处理单元上的不统一问题。

- **研究动机 / 假设**
    - **动机**: 先前研究已证明主题信息对 STS 任务有益。然而，这些研究大多在词或文档层面提取主题，而 Transformer 模型则在子词 (sub-word) 层面处理文本。
    - **假设**: 在子词层面学习潜在主题，并将其与 Transformer 的子词表示相结合，可以创建一个更统一、更强大的句子表示，从而提高 STS 的准确性。统一词汇单元（使用子词）能让主题信息和语义信息在同一分布上进行学习，从而更好地融合。

- **工作内容概览**
    - 论文提出了一种名为 SubTST (Sub-word Latent Topic and Sentence Transformer) 的新方法。该方法继承了 SBERT 的高效 Bi-encoder 架构，但创新地在子词级别学习潜在主题。它通过一个转换层 (Transfer Layer) 将子词主题表示和 Transformer 的输出表示进行融合，然后通过池化操作生成最终的句子嵌入，用于相似度分类。实验结果表明，在多数基准数据集上，SubTST 的性能显著优于 SBERT 和 tBERT 等先进模型。

### 2. 研究方法（含模型 / 技术详解）
- **理论框架与算法**
    - SubTST 的核心框架是一个 **Bi-encoder（孪生网络）** 结构，与 SBERT 类似。对于输入的句子对 (A, B)，模型会独立地为每个句子生成嵌入向量 $u$ 和 $v$，然后将这两个向量以及它们的差向量 $|u-v|$ 拼接后，送入一个 Softmax 分类器进行判断。
    - 算法的关键在于句子嵌入的生成过程，该过程统一了主题模型和 Transformer 模型的处理单元（子词），并设计了专门的融合机制。

- **关键模型/技术逐一说明：架构、输入输出、训练或推理流程、优势与局限**
    - **SubTST 模型架构**:
        1.  **输入**: 一对句子 (Sentence A, Sentence B)。
        2.  **独立编码**: 每个句子独立通过以下流程（以句子 A 为例）：
            - **子词切分**: 句子 A 被切分为一系列子词 (sub-words)。
            - **并行表示学习**:
                - **主题模型 (Topic Model)**: 使用 LDA 模型对子词序列进行处理，为每个子词生成一个主题分布向量。最终得到一个主题矩阵 $M_t$，其维度为 `(主题数 k, 子词数 N_s)`。
                - **Transformer 模型**: 使用预训练的 $BERT_{base}$ 模型处理同一子词序列，得到每个子词的上下文嵌入。最终得到一个语义矩阵 $M_c$，其维度为 `(BERT隐藏层维度 m, 子词数 N_s)`。
            - **表示融合**:
                - **拼接 (Concatenation)**: 将主题矩阵 $M_t$ 和语义矩阵 $M_c$ 沿特征维度拼接，形成一个组合矩阵 $M_{ct}$，维度为 `(m+k, N_s)`。
                - **转换层 (Transfer Layer)**: 将组合矩阵 $M_{ct}$ 输入一个由前馈网络 (Feed-forward)、Dropout 和层归一化 (Layer Normalization) 构成的转换层，进行深度融合和提炼，得到最终的子词表示矩阵 $h$。
            - **池化 (Pooling)**: 对转换后的矩阵 $h$ 进行池化操作（论文实验了 Mean 和 Max 两种策略），将所有子词的表示聚合成一个固定维度的句子嵌入向量 $u$（维度为 $m+k$）。
        3.  **分类**:
            - 对句子 B 执行同样的操作得到向量 $v$。
            - 将 $u$, $v$, 和它们的元素差值 $|u-v|$ 拼接。
            - 将拼接后的向量送入一个带有 Softmax 激活函数的全连接层，输出相似/不相似的概率。
    - **优势**:
        - **统一词汇单元**: 通过在子词级别建模主题，解决了主题模型和 Transformer 模型处理单元不一致的问题，使信息融合更自然。
        - **高效推理**: 继承自 SBERT 的 Bi-encoder 架构使得推理速度远快于 tBERT 等 Cross-encoder 模型，适合需要处理大规模句子对的实际应用。
        - **减少未知词 (OOV)**: 在子词层面建模主题，能显著减少 topic model 在应用于新语料时遇到的“词汇表外”问题。
    - **局限**:
        - Bi-encoder 架构在句子对的交互上不如 Cross-encoder 充分。在某些特定数据集（如小样本且富含命名实体的 MSRP）上，性能可能不及 tBERT。

- **重要公式**
    - 主题模型输出: $M_{t} = \text{TopicModel}(s) \in R^{k \times N_{s}}$
    - Transformer 输出: $M_{c} = \text{Transformer}(\text{sentence}) \in R^{m \times N_{s}}$
    - 拼接: $M_{ct} = \begin{pmatrix} M_{c} \\ M_{t} \end{pmatrix} \in R^{(m+k) \times N_{s}}$
    - 转换层: $h = \text{LayerNorm}(\text{Dropout}(W M_{ct} + B))$
    - 池化 (以 Mean 为例): $u = \text{MEAN}(h)$
    - 分类器: $O = \text{softmax}(W_{t}(u, v, |u-v|))$

### 3. 实验设计与结果（含创新点验证）
- **实验 / 仿真 / 原型流程**
    1.  **数据准备**: 选用 Quora, MSRP, SemEval CQA (Subtask A & B) 数据集，并根据 tBERT 的研究为每个数据集确定最优主题数（Quora: 90, MSRP: 80, SemEval A: 70, SemEval B: 80）。
    2.  **模型配置**:
        - **基线模型**: SBERT ($BERT_{base}$)、tBERT ($BERT_{base}$)、SwissAlps、KeLP。
        - **SubTST 配置**:
            - 使用 $BERT_{base}$ 作为 Transformer backbone。
            - 使用 LDA 作为主题模型。
            - 测试两种池化策略：`mean` 和 `max`。
            - 测试两种主题嵌入状态：`frozen`（固定不变）和 `train topic`（在训练中微调）。这产生了四种组合：`SubTST-mean`, `SubTST-max`, `SubTST-mean-train topic`, `SubTST-max-train topic`。
    3.  **训练**: 在各个数据集的训练集上，以分类任务的形式（优化 Softmax 输出的交叉熵损失）对模型进行微调，共训练 6 个 epoch。
    4.  **评估**: 在测试集上使用准确率 (Accuracy) 和 F1-score 指标评估模型性能，并与基线模型进行比较。同时在开发集上观察训练过程中的 F1-score 变化曲线。

- **数据集、参数、评价指标**
    - **数据集**:
        - **Quora**: 约 40 万个问题对，判断是否为重复问题。
        - **MSRP**: 约 5000 个句子对，判断是否为转述。
        - **SemEval CQA (A)**: 约 2.6 万个“问题-评论”对，判断评论是否对问题有帮助。
        - **SemEval CQA (B)**: 约 4000 个“问题-问题”对，判断两个问题是否相关。
    - **参数**: 主题数 k 根据数据集而定 (70-90)；BERT 隐藏层维度 m 为 768；训练 epoch 数为 6。
    - **评价指标**: Accuracy 和 F1-score。

- **创新点如何得到验证，结果对比与可视化描述**
    - **创新点验证**: “在子词级别融合主题信息是有效的”这一核心创新点，通过 SubTST 与两个关键基线的对比得到验证：
        1.  **对比 SBERT**: SubTST 在 SBERT (也是 Bi-encoder) 的基础上增加了子词主题信息。实验结果显示，几乎所有配置的 SubTST 在 F1-score 上都优于 SBERT，证明了增加子词主题信息的有效性。例如，在 Quora 数据集上，SubTST-mean-train topic 的 F1-score 达到 90.7，高于 SBERT-mean 的 89.9。
        2.  **对比 tBERT**: tBERT 使用的是在词/文档级别的主题信息和更强大的 Cross-encoder 架构。尽管 SubTST 使用了理论上交互较弱的 Bi-encoder 架构，但在 Quora、SemEval A 和 SemEval B 数据集上，其性能仍然优于或持平于 tBERT。例如，在 SemEval A 上，SubTST-mean-train topic 的 F1-score 为 77.8，高于 tBERT 报告的 76.8。这有力地证明了**在子词级别统一和融合信息**带来的巨大优势，足以弥补 Bi-encoder 架构本身的不足。

    - **可视化描述**: 论文中的 Figure 3 展示了模型在开发集上随训练 epoch 变化的 F1-score 曲线。
        - **稳定性与收敛速度**: 图表显示，SubTST 模型（特别是 `SubTST-mean-train topic`）通常在 1-2 个 epoch 内就能达到性能峰值，并且后续曲线非常平稳。相比之下，tBERT 的曲线波动可能更大。这表明 SubTST 的训练过程更稳定、收敛更快，作者将其归因于统一词汇单元带来的好处。

- **主要实验结论与作者解释**
    - **主要结论**: SubTST 在大多数基准测试中显著优于 SBERT 和 tBERT。`mean` 池化策略通常优于 `max` 策略。允许主题嵌入被微调（`train topic`）的版本通常性能最佳。
    - **作者解释**:
        - **对 MSRP 表现不佳的解释**: 在 MSRP 数据集上，tBERT 表现更好。作者认为这是因为 MSRP 数据量小且包含大量命名实体，tBERT 的 Cross-encoder 架构（具有完全的自注意力机制）在这种情况下更具优势。
        - **对 SemEval Subtask B 异常的解释**: 在此任务中，使用冻结主题嵌入的 SubTST (`F1=61.2`) 反而优于可训练的版本 (`F1=54.2`)。作者推测，这可能是因为该任务的句子对（问题-问题）长度通常很长，这一特殊性导致了不同的模型表现。

### 4. 研究结论
- **重要发现（定量 / 定性）**
    - **定量**: SubTST 模型在多个 STS 基准数据集上取得了 SOTA (state-of-the-art) 的性能。例如，在 Quora 数据集上 F1-score 达到 90.7，在 SemEval A 上达到 77.8。
    - **定性**: 论文通过实证研究证明，将主题模型和 Transformer 模型的处理单元统一在子词 (sub-word) 级别，是一种非常有效的表示学习和融合策略。这种方法不仅提升了模型性能，还加快了收敛速度并增强了训练的稳定性。

- **对学术或应用的意义**
    - **学术意义**: 为如何在 Transformer 时代有效利用经典的主题模型提供了新的思路。它揭示了“统一数据分布”或“统一词汇级别”对于学习主题表示和语义表示的重要性，为该领域的后续研究提供了支持。
    - **应用意义**: SubTST 模型兼具高性能和高效率。其 Bi-encoder 架构使其在处理大规模信息检索、句子匹配等实际应用时，推理速度远快于 Cross-encoder 模型，具有很高的实用价值。

### 5. 创新点列表
1.  **核心思想创新**: 首次提出在 **子词 (sub-word)** 级别学习潜在主题，并将其用于语义相似度检测，而非传统的词或文档级别。
2.  **统一词汇单元**: 将主题模型的基本处理单元与 Transformer 模型对齐，解决了两者在基础表示上的不一致问题，促进了更深层次的特征融合。
3.  **新颖的融合架构 (SubTST)**: 设计了一种新的 Bi-encoder 模型，通过一个专门的 **转换层 (Transfer Layer)** 来有效融合子词的语义表示和主题表示，生成了更具判别力的句子嵌入。
4.  **性能与效率的平衡**: 证明了通过巧妙的特征融合，一个计算上更高效的 Bi-encoder 架构可以在多个任务上超越计算密集的 Cross-encoder 架构（如 tBERT），实现了性能和效率的双赢。
5.  **训练稳定性和快速收敛**: 实验证明，该方法不仅性能优越，而且训练过程更加稳定，能更快地达到最佳性能。

=============================《文章分隔符》=============================

 # 跨学科语义漂移识别与可视化分析 (2023年10月)

### 1. 研究目标 · 内容 · 问题 · 出发点
- **研究领域与背景、具体对象 / 数据集**
    - **研究领域与背景**：本研究位于信息科学、计算语言学与数字人文交叉领域。背景是随着学科交叉融合，领域术语在不同学科间的语义漂移现象日益增多，影响了数据挖掘和知识发现的准确性。现有研究多关注时间维度的语义漂移，对跨学科维度的系统性研究较少。
    - **具体对象 / 数据集**：研究对象为图书情报领域的专业术语及其在不同学科中的定义。实验数据首先来源于18本图书情报领域CSSCI期刊2010-2020年的文献摘要，从中提取了1731个高频核心术语；然后，通过“术语在线”平台获取了其中773个术语的2489条跨学科官方审定定义，并基于此构建了用于实验的人工标注数据集`DT-Sentence`。

- **论文想解决的核心问题**
    - 如何有效地识别和度量一个领域术语在不同学科中所发生的语义内涵变化（即跨学科语义漂移）。
    - 现有方法多依赖静态词向量模型（如Word2Vec），无法解决一词多义问题，且缺乏对跨学科视角的深入探讨。论文旨在解决这些局限，提出一种基于深度学习的、更高精度的识别与可视化方案。

- **研究动机 / 假设**
    - **动机**：正确理解和揭示领域术语的语义漂移现象，有助于挖掘知识演化的规律，并为语义理解、语义建模等下游应用提供技术基础。
    - **假设**：通过结合深度学习模型（SBERT）与专家知识（官方术语定义），可以更准确地表征术语的深层语义。基于此，通过向量聚类能够有效地区分一个术语在不同学科中的语义是否一致，从而判定其是否发生漂移。

- **工作内容概览**
    - 论文设计并实现了一个完整的领域术语跨学科语义漂移识别与可视化技术框架。该框架包含四个核心模块：
        1.  **数据收集与处理**：从学术文献中提取候选术语，并爬取其在各学科的官方定义，构建语料库。
        2.  **语义漂移识别**：采用“SBERT模型 + BERT-Whitening优化 + 层次聚类”的组合算法，对术语的多条定义进行聚类，根据聚类结果判定其是否为语义漂移词。
        3.  **语义漂移度量**：使用余弦距离计算术语定义向量间的差异，量化语义漂移的程度。
        4.  **语义漂移可视化**：结合主成分分析（PCA）降维和Bokeh库，对术语的语义聚类结果进行二维交互式可视化。

### 2. 研究方法（含模型 / 技术详解）
- **理论框架与算法**
    - 论文的技术框架遵循“语义表征 -> 漂移识别 -> 漂移度量 -> 可视化分析”的流程。其核心算法是一个组合模型，即利用`SBERT`将术语的各学科定义文本转化为高质量的句向量，接着使用`BERT-Whitening`对向量进行优化，最后通过`层次聚类算法`根据向量的相似性对定义进行分组，从而识别语义漂移。

- **关键模型/技术逐一说明**
    - **SBERT (Sentence-BERT)**
        - **架构**：采用孪生网络（Siamese Network）结构，包含两个参数共享的BERT模型。该结构专门为句子对的相似度计算任务而优化。
        - **推理流程**：将单个术语定义（一个句子）输入SBERT模型，模型对BERT输出的词向量进行平均池化（Mean-Pooling），生成一个能够代表整个句子语义的固定维度向量（句向量）。
        - **输入/输出**：输入为术语定义的文本字符串，输出为一个高维（如768维）的密集向量。
        - **优势**：相较于原生BERT通过简单平均词向量的方式，SBERT生成的句向量在语义相似度计算和聚类任务上表现更优且效率更高，因为它经过了专门的微调训练。

    - **BERT-Whitening**
        - **架构**：这是一种对SBERT生成的句向量进行后处理的技术。
        - **流程**：首先，收集所有术语定义生成的句向量集合 $\{x_i\}_{i=1}^N$。然后，利用主成分分析（PCA）对这些向量进行处理，使其均值为0，协方差矩阵为单位阵（即“白化”）。这可以解决句向量分布各向异性（anisotropic）的问题。
        - **优势**：该方法能解决语义相似度计算中的“坐标对齐”问题，去除冗余信息，提升语义表示的效果和检索速度。

    - **层次聚类算法 (Hierarchical Clustering)**
        - **架构**：一种无监督聚类算法，采用凝聚法（Agglomerative）进行。
        - **流程**：开始时，将一个术语的每条定义向量都视为一个独立的簇。然后，在每一步迭代中，计算所有簇之间的距离（相似度），并将距离最近的两个簇合并成一个新簇。这个过程不断重复，直到簇间的距离超过一个预设的阈值。
        - **漂移判定规则**：如果某术语的所有定义向量最终被聚为1类，则判定其为“语义稳定词”；如果聚类结果大于1类，则为“语义漂移词”。

- **重要公式**
    - **专家知识表示**:
      $$k = \{w, \langle(s_1, \text{sub}_1), (s_2, \text{sub}_2), \dots, (s_n, \text{sub}_n)\rangle\}$$
      其中，$w$是术语，$s$是定义文本，$\text{sub}$是其所属的学科标签。

    - **跨学科语义漂移度 ($\zeta(w)$)**:
      $$\zeta(w) = 1 - \frac{\sum \text{cos}(\vec{w_i}, \vec{w_j})}{C_n^2}, \quad 1 \le i < j \le n$$
      其中，$\{\vec{w_1}, \vec{w_2}, \dots, \vec{w_n}\}$ 是术语 $w$ 在 $n$ 个不同定义下的向量表示，$\text{cos}(\cdot)$为余弦相似度，$C_n^2$ 是定义向量对的总数。该值越大，表示语义差异越大，漂移程度越高。

### 3. 实验设计与结果（含创新点验证）
- **实验流程**
    1.  **数据准备**：从18种图情领域CSSCI期刊的49,164篇文献摘要（2010-2020）中，通过TF-IDF提取并筛选出1,731个高频候选术语。
    2.  **语料库构建**：从“术语在线”平台获取上述术语的官方定义，最终得到773个术语的2489条跨学科定义，并手动为这些定义标注语义类别（含义相同的定义标为同一类），构建`DT-Sentence`数据集。
    3.  **向量化与优化**：使用SBERT模型将2489条定义文本转换为句向量，并应用BERT-Whitening方法对所有向量进行优化。
    4.  **聚类与识别**：对每个拥有多条定义的术语，将其优化后的定义向量输入层次聚类算法。根据聚类结果（大于1类则为漂移）进行判定。
    5.  **评估与对比**：将模型的识别结果与人工标注的`DT-Sentence`数据集进行比较，计算精确率、召回率和F1值，并与RoBERTa和DistilBERT两个基线模型进行对比。
    6.  **分析与可视化**：计算已识别出的语义漂移词的漂移度，并选取典型案例（如“本体”、“信息化”）进行PCA降维和Bokeh可视化展示。

- **数据集、参数、评价指标**
    - **数据集**：`DT-Sentence`数据集，包含773个术语的2489条人工标注的多学科定义。
    - **参数**：层次聚类算法的距离阈值设为`0.7`。该值通过分析聚类树状图（选择能分割大类的最长垂直线）和抽样测试（语义漂移术语的定义间余弦相似度大多在0.7以下）联合确定。
    - **评价指标**：精确率 (P), 召回率 (R), F1值 (F1-score)。

- **创新点如何得到验证，结果对比与可视化描述**
    - **创新点验证**：本文方法（SBERT+Whitening）的有效性通过与另外两种先进的预训练模型（RoBERTa, DistilBERT）在同一数据集上的性能对比得到验证。
    - **结果对比**：
| 方法 | P/% | R/% | F1/% |
| :--- | :---: | :---: | :---: |
| RoBERTa | 85.05 | 88.48 | 86.71 |
| DistilBERT | 85.77 | 88.97 | 87.33 |
| **SBERT+Whitening(本文)** | **86.15** | **91.06** | **88.59** |
    该结果表明，本文提出的方法在各项指标上均优于对比方法。
    - **可视化描述**：
        - 以术语“**本体**”为例，其6条定义在PCA降维后的二维空间中清晰地分成了**3个簇**，直观地证明了其在不同学科群（如信息科学、植物学）中发生了语义漂移。
        - 与之相反，术语“**信息化**”的4条定义，虽然文本描述略有不同，但在可视化图中紧密地聚合为**1个簇**，表明其在各学科中语义统一，属于语义稳定词。这些可视化结果与模型的判定一致，验证了方法的可解释性。

- **主要实验结论与作者解释**
    - 实验证明，所提出的`SBERT+Whitening+层次聚类`框架能够准确识别跨学科语义漂移，F1值达到88.59%。
    - 作者发现，一个术语涉及的学科越多，其发生语义漂移的概率越大。例如，拥有超过4种定义的术语中，84.88%被识别为语义漂移词。
    - 语义漂移度的计算结果与定性分析吻合，语义稳定词（如“图书馆学”，0.062）的漂移度远低于语义漂移词（如“计量”，0.456）。

### 4. 研究结论
- **重要发现**
    - **定量发现**：
        - 提出了一种高精度（F1值为88.59%）的跨学科语义漂移自动识别方法。
        - 证实了术语的跨学科使用广度与其语义漂移倾向呈正相关。
    - **定性发现**：
        - 总结了导致语义漂移的四大成因：学科特性差异、时间因素演变、认知主体差异（如同词异译）、以及语言表达形式的表面差异。
        - 以图情学科为例，通过词云分析发现其与计算机科学、管理科学技术的术语共享和内涵一致性最高，而与其他学科（如教育学、语言学）则存在较多同名但异义的术语，揭示了学科交叉融合的具体路径和模式。

- **对学术或应用的意义**
    - **学术意义**：为语义漂移研究提供了新的视角（跨学科）和更有效的技术手段（深度学习+专家知识），为认知语言学和计算术语学的相关研究提供了参考。
    - **应用意义**：该框架有助于提升依赖术语理解的应用（如信息检索、知识图谱构建、科技文献分析）的准确性，为消除跨学科交流中的语义障碍奠定了技术基础。

### 5. 创新点列表
- **视角创新**：将语义漂移的研究重点从传统的时间维度（历时性）系统性地转向了跨学科维度，填补了相关研究的空白。
- **方法创新**：提出并验证了一种“SBERT模型 + BERT-Whitening优化 + 层次聚类”的组合算法，相比传统的静态词向量模型，能更精准地处理一词多义和复杂语境下的语义漂移识别。
- **数据源创新**：以经过领域专家审定的官方“术语定义”作为核心分析语料，将专家知识显式地融入语义表征过程，提高了语义分析的准确性和权威性。
- **框架整合创新**：构建了一套集识别、度量、可视化于一体的完整分析框架，不仅能判断是否漂移，还能量化漂移程度并直观展示漂移情况，为深入探究语义漂移的规律和成因提供了全方位的工具支持。
